<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="Shiyue Xu">
    <link rel="icon" href="./assets/img/favicons_shield.gif">

    <title>TEAM: Trauma Error Analysis & Management</title>

    <!-- Bootstrap core CSS -->
    <link href="./assets/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="./assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]>
    <script src="./assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="./assets/js/ie-emulation-modes-warning.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Custom styles for this template -->
    <link href="./assets/css/Navbar.css" rel="stylesheet">
    <link href="./assets/css/MyCSS.css" rel="stylesheet">
</head>

<!-- NAVBAR
================================================== -->
<body>
<div class="navbar-wrapper">
    <div class="container">
        <nav class="navbar navbar-inverse navbar-static-top">
            <div class="container">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
                            aria-expanded="false" aria-controls="navbar">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <div class="navbar-logo">
                        <a class="logo-link" href="index.html"><img class="navbar-logo-img"
                                                                    src="./assets/img/RU_Logo.png"
                                                                    alt="Rutgers"></a>
                    </div>
                </div>
                <div id="navbar" class="navbar-collapse collapse">
                    <ul class="nav navbar-nav">
                        <li><a href="./index.html">HOME</a></li>
                        <li><a href="./Members.html">MEMBERS</a></li>
                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button"
                               aria-haspopup="true"
                               aria-expanded="false">PROJECTS <span class="caret"></span></a>
                            <!--TODO-->
                            <ul class="dropdown-menu">
                                <li class="active"><a href="./AIM1.html">Activity Recognition in Medical Settings</a>
                                </li>
                                <li><a href="./AIM2.html">Visual Interactive Tool on Trace Alignment & Trace
                                    Attribute</a></li>
                                <li><a href="./AIM3.html">Speech Recognition & Understanding in Trauma Resuscitation</a>
                                </li>
                                <li><a href="https://is4health.cci.drexel.edu/">Interactive Systems for Healthcare</a>
                                </li>
                            </ul>
                        </li>
                        <li><a href="./Publications.html">PUBLICATIONS</a></li>
                        <li class="dropdown">
                            <a href="./Resources.html" class="dropdown-toggle" data-toggle="dropdown" role="button"
                               aria-haspopup="true"
                               aria-expanded="false">RESOURCES <span class="caret"></span></a>
                            <ul class="dropdown-menu">
                                <li><a href="./Resources.html#Source_Code">Source Code</a></li>
                                <li><a href="./Resources.html#Data_Set">Data Set</a></li>
                                <li><a href="./Resources.html#Software">Software</a></li>
                            </ul>
                        </li>
                        <li><a href="./Funding.html">FUNDING</a></li>
                        <li><a href="./Contact.html">CONTACT US</a></li>

                    </ul>
                </div>
            </div>
        </nav>

    </div>
</div>

<!-- Content
================================================== -->
<div class="container">
    <div class="jumbotron jumbotron_projects">

        <h2 align="center">Activity Recognition in Medical Settings</h2>

        <p style="margin-top:14px; text-align: justify; text-justify: inter-word;">Our research focused on concurrent
            activity recognition for actual fast-paced medical applications using sensor networks include passive RFID,
            depth sensor, microphone array, etc. We designed the system with shallow classifiers and deep learning based
            structures to predict concurrent medical activities and process phases. We also do side research such as
            people tracking, dynamic room layout mapping which may potential help with the activity recognition.</p>
    </div>

    <div class="row">
        <div class="col-sm-8 blog-main" role="main">

            <br>

            <div class="blog-post">

                <h2 class="Member-header">Members</h2>
                <hr>

                <div class="row">
                    <div class="col-lg-6">

                        <a href="./assets/img/Arthur.JPG" target="view_frame"><img src="./assets/img/Arthur.JPG"
                                                                                   style="width: 25%;float: left; margin-right: 5px"></a>

                        <p style="text-align: left; text-justify: inter-word; float: right; width: 68%">
                            <span class="pub_title">Xinyu Li</span>
                            <br>
                            <span class="pub_authors">Ph.D Student</span>
                            <br>
                            <span class="pub_type">Department of Electrical and Computer Engineering, Rutgers University</span>
                            <a class="btn btn-info btn-xs"
                               href="https://sites.google.com/site/arthurlixinyu/current-project"
                               role="button">More &raquo;</a>

                        </p>

                        <p style="clear:both">&nbsp;</p>

                    </div>

                    <div class="col-lg-6">

                        <a href="./assets/img/yanyi.JPG" target="view_frame"><img src="./assets/img/yanyi.jpg"
                                                                                  style="width: 25%;float: left; margin-right: 5px"></a>

                        <p style="text-align: left; text-justify: inter-word; float: right; width: 68%">
                            <span class="pub_title">Yanyi Zhang</span>
                            <br>
                            <span class="pub_authors">Ph.D Student</span>
                            <br>
                            <span class="pub_type">Department of Electrical and Computer Engineering, Rutgers University</span>
                            <a class="btn btn-info btn-xs" href="#" role="button">More &raquo;</a>

                        </p>

                        <p style="clear:both">&nbsp;</p>

                    </div>
                </div>

                <div class="row">
                    

                    <div class="col-lg-6">

                        <a href="./assets/img/jianyu.jpg" target="view_frame"><img src="./assets/img/jianyu.jpg"
                                                                                   style="width: 25%;float: left; margin-right: 5px"></a>

                        <p style="text-align: left; text-justify: inter-word; float: right; width: 68%">
                            <span class="pub_title">Jianyu Zhang</span>
                            <br>
                            <span class="pub_authors">Master Student</span>
                            <br>
                            <span class="pub_type">Department of Electrical and Computer Engineering, Rutgers University</span>
                            <a class="btn btn-info btn-xs" href="#" role="button">More &raquo;</a>

                        </p>

                        <p style="clear:both">&nbsp;</p>

                    </div>
					
					<div class="col-lg-6">

                        <a href="./assets/img/yehan.jpg" target="view_frame"><img src="./assets/img/yehan.jpg"
                                                                                    style="width: 25%;float: left; margin-right: 5px"></a>

                        <p style="text-align: left; text-justify: inter-word; float: right; width: 68%">
                            <span class="pub_title">Yehan Wang</span>
                            <br>
                            <span class="pub_authors">Master Student</span>
                            <br>
                            <span class="pub_type">Department of Electrical and Computer Engineering, Rutgers University</span>
                            <a class="btn btn-info btn-xs"
                               href="#"
                               role="button">More &raquo;</a>

                        </p>

                        <p style="clear:both">&nbsp;</p>

                    </div>
                </div>
				
				

                <div class="row">
                    <div class="col-lg-6">

                        <a href="./assets/img/kaixiang.jpg" target="view_frame"><img src="./assets/img/kaixiang.jpg"
                                                                                   style="width: 25%;float: left; margin-right: 5px"></a>

                        <p style="text-align: left; text-justify: inter-word; float: right; width: 68%">
                            <span class="pub_title">Kaixiang Wang</span>
                            <br>
                            <span class="pub_authors">Master Student</span>
                            <br>
                            <span class="pub_type">Department of Electrical and Computer Engineering, Rutgers University</span>
                            <a class="btn btn-info btn-xs" href="#" role="button">More &raquo;</a>

                        </p>

                        <p style="clear:both">&nbsp;</p>

                    </div>
                </div>

            </div>

            <br>

            <div class="blog-post">

                <h2 class="Member-header">Previous Student</h2>
                <hr>
                <!-- Three columns of text below the carousel -->
                <ul>
                    <li>
                        Dongyang Yao (Graduated in 2016 Summer)
                    </li>
                   <br>
                    <li>
                        Xuechao Pan (Graduated in 2016 Summer)
                    </li>
                    <br>
                    <li>
                        Renyi Hu (Graduated in 2015 Summer)
                    </li>
					<br>
                    <li>
                        Mengzhu Li (Graduated in 2016 Fall)
                    </li>
                    <br>
                    <li>
                        Shiyue Xu (Graduated in 2017 Spring)
                    </li>
                    <br>
					<li>
                        Yueyang Chen (Graduated in 2017 Fall)
                    </li>
                   
                </ul>
                <!--<div class="row">-->
                <!-- -->
                <!--</div>-->

            </div>

            <br>

            <div class="blog-post">
                <h2 class="Member-header">Project & Publications</h2>
                <hr>

                <a href="./assets/img/Tagging%20Strategies.jpg" target="view_frame"><img
                        src="./assets/img/Tagging%20Strategies.jpg"
                        style="width: 49%;float: right"></a>

                <p style="text-align: justify; text-justify: inter-word; float: left; width: 49%">
                    <span class="pub_title">Activity Recognition for Medical Teamwork Based on Passive RFID</span>
                    <br>
          <span class="pub_authors">Xinyu Li, Dongyang Yao, Xuechao Pan, Jonathan Johannaman, JawWon Yang, Rachel Webman, Aleksandra Sarvevic, Ivan Marsic, Randal S. Burd
          </span>
                    <br>
                    <br>
                    <span class="pub_type">We describe a novel and practical activity recognition system for dynamic and complex medical settings using only passive RFID technology. Our activity recognition approach is based on the use of objects that are specific for a given activity. The object-use status is detected from RFID data and the activities are predicted from the statuses of use of different objects. We tagged 10 objects in a trauma room of an emergency department and recorded RFID data for 10 actual trauma resuscitations. More than 20,000 seconds of data were collected and used for analysis. The system achieved a 96% overall accuracy with a 0.74 F-score for detecting use of 10 common resuscitation objects and 95% accuracy with a 0.30 F-Score for activity recognition of 10 medical activities.</span>
                    <br>
                </p>

                <p style="clear:both">&nbsp;</p>
                <br>

                <p style="text-align: justify; text-justify: inter-word; float: left; width: 49%">
                    <span class="pub_title">Privacy Preserving Dynamic Room Layout Mapping</span>
                    <br>
                    <span class="pub_authors">Xinyu Li, Yanyi Zhang, Ivan Marsic, Randal S. Burd</span>
                    <br>
                    <br>
                    <span class="pub_type">We present a novel and efficient room layout mapping strategy that does not reveal people’s identity. The system uses only a Kinect depth sensor instead of RGB cameras or a high-resolution depth sensor. The users’ facial details will neither be captured nor recognized by the system. The system recognizes and localizes 3D objects in an indoor environment, that includes the furniture and equipment, and generates a 2D map of room layout. We evaluated this system in two challenging real-world application scenarios: a laboratory room with four people present and a trauma room with up to 10 people during actual trauma resuscitations. The system achieved 80% object recognition accuracy with 9.25 cm average layout mapping error for the laboratory furniture scenario and 82% object recognition accuracy for the trauma resuscitation scenario during six actual trauma cases.</span>
                    <br>
                </p>

                <iframe width="49%" height="300px" src="https://www.youtube.com/embed/I459Lse9BWY" frameborder="0"
                        allowfullscreen align="right"></iframe>

                <p style="clear:both">&nbsp;</p>

                <a href="./assets/img/CNN_Pooling.png" target="view_frame"><img src="./assets/img/CNN_Pooling.png"
                                                                                style="width: 49%;float: right"></a>

                <p style="text-align: justify; text-justify: inter-word; float: left; width: 49%">
           <span class="pub_title">Deep Neural Network for RFID-Based Activity Recognition
           </span>
                    <br>
           <span class="pub_authors">Xinyu Li, Yanyi Zhang, Mengzhu Li, Ivan Marsic, Jaewon Yang, Randall S. Burd
           </span>
                    <br>
                    <br>
           <span class="pub_type">We propose a Deep Neural Network (DNN) structure for RFIDbased activity recognition. RFID data collected from several reader antennas with overlapping coverage have potential spatiotemporal relationships that can be used for object tracking. We augmented the standard fully-connected DNN structure with additional pooling layers to extract the most representative features. For model training and testing, we used RFID data from 12 tagged objects collected during 25 actual trauma resuscitations. Our results showed 76% recognition micro-accuracy for 7 resuscitation activities and 85% average micro-accuracy for 5 resuscitation phases, which is similar to existing system that, however, require the user to wear an RFID antenna.
           </span>
                    <br>
                </p>

                <div style="float: right">
                    <p style="float: right"><a class="btn btn-default" href="./Publications.html#paper_DNN"
                                               role="button">Paper &raquo;</a>
                    </p>

                    <!--<p><a class="btn btn-default"-->
                    <!--href="https://github.com/Arthurlxy/DNN-with-Pooling.git" role="button">Source-->
                    <!--Code &raquo;</a>-->
                    <!--</p>-->
                </div>

                <p style="clear:both">&nbsp;</p>

                <p style="text-align: justify; text-justify: inter-word; float: left; width: 49%">
          <span class="pub_title">Online Process Phase Detection Using Multimodal Deep Learning
          </span>
                    <br>
                    <br>
          <span class="pub_authors">Xinyu Li, Yanyi Zhang, Mengzhu Li, Shuhong Chen, Farneth R. Austin, Ivan Marsic, Randall S. Burd
          </span>
                    <br>
          <span class="pub_type">We present a multimodal deep-learning structure that automatically predicts phases of the trauma resuscitation process in real-time. The system first pre-processes the audio and video streams captured by a Kinect’s built-in microphone array and depth sensor. A multimodal deep learning structure then extracts video and audio features, which are later combined through a “slow fusion” model. The final decision is then made from the combined features through a modified softmax classification layer. The model was trained on 20 trauma resuscitation cases (˃13 hours), and was tested on 5 other cases. Our results showed over 80% online detection accuracy with 0.7 F-Score, outperforming previous systems.
          </span>
                    <br>
                </p>

                <iframe width="49%" height="300px" src="https://www.youtube.com/embed/p3MzFN3i_eU" frameborder="0"
                        allowfullscreen align="right"></iframe>

                <p style="clear:both">&nbsp;</p>

                <a href="./assets/img/Antenna%20Map.jpg" target="view_frame"><img src="./assets/img/Antenna%20Map.jpg"
                                                                                  style="width: 49%;float: right"></a>

                <p style="text-align: justify; text-justify: inter-word; float: left; width: 49%">
      <span class="pub_title">Deep Learning for RFID-Based Activity Recognition
      </span>
                    <br>
                    <br>
      <span class="pub_authors">Xinyu Li, Yanyi Zhang, Ivan Marsic, Aleksandra Sarcevic, Randall S. Burd
      </span>
                    <br>
      <span class="pub_type">We present a system for activity recognition from passive RFID data using a deep convolutional neural network. We directly feed the RFID data into a deep convolutional neural network for activity recognition instead of selecting features and using a cascade structure that first detects object use from RFID data followed by predicting the activity. Because our system treats activity recognition as a multi-class classification problem, it is scalable for applications with large number of activity classes. We tested our system using RFID data collected in a trauma room, including 14 hours of RFID data from 16 actual trauma resuscitations. Our system outperformed existing systems developed for activity recognition and achieved similar performance with process-phase detection as systems that require wearable sensors or manually-generated input. We also analyzed the strengths and limitations of our current deep learning architecture for activity recognition from RFID data.
      </span>
                    <br>
                </p>

                <a href="./assets/img/CNN%20for%20RFID.png" target="view_frame"><img
                        src="./assets/img/CNN%20for%20RFID.png"
                        style="width: 49%;float: right"></a>

                <p style="clear:both">&nbsp;</p>

            </div>

        </div>

        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">

            <div class="sidebar-module">
                <h4>What's New!</h4>
                <ul>
                    <li>
                        <span class="pub_title">Sep, 2, 2016</span><br>
                        Xinyu got the school of engineering conference travel award (2016 July).
                    </li>
                    <li>
                        <span class="pub_title">Aug, 31, 2016</span><br>
                        Paper "Online Process Phase Detection Using Multimodal Deep Learning" is accepted by IEEE UEMCON
                        2016, I
                        will give an oral presentation.
                    </li>
                    <li>
                        <span class="pub_title">July, 18, 2016</span><br>
                        Paper "Deep Learning for RFID-Based Activity Recognition" is accepted by Sensys 2016.
                    </li>
                    <li>
                        <span class="pub_title">June, 24, 2016</span><br>
                        Paper "Deep Neural Network for RFID Based Activity Recognition" is submitted to ACM S3 workshop.
                    </li>
                    <li>
                        <span class="pub_title">June, 22, 2016</span><br>
                        Paper "VIT-PLA: Visual Interactive Tool for Process Log Analysis" was accepted, I am the
                        co-author of the
                        paper.
                    </li>
                    <li>
                        <span class="pub_title">May, 27, 2016</span><br>
                        Submitted two papers as co-author
                    </li>
                    <li>
                        <span class="pub_title">May, 4, 2016</span><br>
                        I got the IEEE student travel grant to support my travel to IEEE RFID 2016.
                    </li>
                    <li>
                        <span class="pub_title">April, 16, 2016</span><br>
                        My paper "Activity Recognition for Medical Teamwork Based on Passive RFID" is nominated for best
                        paper award
                        in IEEE RFID 2016 conference. Details
                    </li>
                    <li>
                        <span class="pub_title">March, 16, 2016</span><br>
                        My paper "Privacy preserving dynamic room layout mapping" is accepted by ICISP 2016.
                    </li>
                </ul>
            </div>

        </div>
    </div>
</div>


<!-- Bootstrap core JavaScript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="./assets/js/vendor/jquery.min.js"><\/script>')</script>
<script src="./assets/bootstrap/dist/js/bootstrap.min.js"></script>
<!-- Just to make our placeholder images work. Don't actually copy the next line! -->
<script src="./assets/js/vendor/holder.min.js"></script>
<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
<script src="./assets/js/ie10-viewport-bug-workaround.js"></script>
</body>
</html>
